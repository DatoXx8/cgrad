#include <CL/cl.h>
#include <assert.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "nn.h"
#include "runtimes/cl.h"
#include "tensor.h"
#include "utils.h"

/*
 *  TODO: Support `global_size > 1`. surprisingly not trivial cuz of race conditions
 *  TODO: Add multi-thread c runtime
 *  TODO: Make reduce backprop real and not fake.
 *  TODO: Maybe remove explicit backprop and make autograd things.
 *  TODO: FLOP/S estimator.
 *  TODO: Update README with installation and usage guides.
 *  TODO: Make layers that generate their own weights from the input activations and meta-weights (Do this multiple
 * times?)
 *  TODO: Investigate OpenCL apparent memory leaks. Valgrind does not find memory leaks in my code but still the memory
 * usage is *super* high and seems to be rising. Also investige the OpenCL compiler being stupidly slow
 *  TODO: Make OpenCL opt-out with a -U<macro> flag (Unsure about this one cuz it makes the code very ugly)
 *  TODO: Train solely on chess960 self play. Bunch of different heads with a core net. Piece placing chess is very
 * interesting. Generate the training data with a smaller lower quality net (possibly don't even search at all and just
 * have sample from a policy generated by the net) and then train the big net by search training
 *  TODO: Make a go engine.
 *  TODO: Make string helper functions in a string.c and string.h (Should probably do this first to avoid a bunch of
 * string weirdnes when I forget to remove a `*` somewhere and have another debugging nightmare)
 */

void usage_print(const char *program) {
    assert(program);
    printf("USAGE: %s <c|cl>\n", program);
}

int main(int argc, const char **argv) {
    // const uint32_t RNG = time(NULL);
    const uint32_t RNG = 0;
    printf("INFO: RNG Seed %u\n", RNG);
    srand(RNG);
    compile_e compile_type;
    if(argc < 2) {
        usage_print(argv[0]);
        ERROR("Program expects an argument\n");
    } else if(argc > 2) {
        usage_print(argv[0]);
        ERROR("Program expects less arguments\n");
    }
    if(!strncmp(argv[1], "-cl", 3)) {
        printf("INFO: Using OpenCL\n");
        compile_type = compile_cl;
    } else if(!strncmp(argv[1], "-c", 2)) {
        printf("INFO: Not using OpenCL\n");
        compile_type = compile_none;
    } else {
        usage_print(argv[0]);
        ERROR("Invaling argument\n");
    }
    cl_device_id device_id;
    cl_context context;
    if(compile_type == compile_cl) {
        int err;
        device_id = cl_device_get();
        context = clCreateContext(NULL, 1, &device_id, NULL, NULL, &err);
    } else {
        context = NULL;
    }

    INIT_TIMER();
    START_TIME();

    const double LEARNING = 1e-2;
    const int64_t SAMPLES = 1;
    const int64_t LAYERS = 5;
    const int64_t INPUT_Z = 2;
    const int64_t INPUT_Y = 4;
    const int64_t INPUT_X = INPUT_Y;
    layerconfig_t *layerconfig = calloc(LAYERS, sizeof(layerconfig_t));
    assert(layerconfig);
    layerconfig_t l0 = {
        .layer_type = layer_input,
        .input_z = INPUT_Z,
        .input_y = INPUT_Y,
        .input_x = INPUT_X,
    };
    layerconfig_t l1 = {
        .layer_type = layer_convolution,
        .norm_type = norm_none,
        .convolution_filters = 2,
        .convolution_kernel_size = 3,
        .convolution_kernel_stride = 1,
        .convolution_kernel_padding = 1,
        .activation_function = activation_none,
    };
    layerconfig_t l2 = {
        .layer_type = layer_split,
        .norm_type = norm_none,
        .split_filters = 2,
        .activation_function = activation_none,
    };
    layerconfig_t l3 = {
        .layer_type = layer_reduce,
        .reduce_type = layer_reduce_max,
        .reduce_kernel_size = 2,
        .reduce_kernel_stride = 1,
    };
    layerconfig_t l4 = {
        .layer_type = layer_dense,
        .norm_type = norm_none,
        .dense_output_size = 3,
        .activation_function = activation_none,
    };
    layerconfig[0] = l0;
    layerconfig[1] = l1;
    layerconfig[2] = l2;
    layerconfig[3] = l3;
    layerconfig[4] = l4;

    neuralnet_t neuralnet = neuralnet_alloc(LAYERS, layerconfig, LEARNING, compile_type);
    tensor_t input = tensor_alloc(SAMPLES, NEURALNET_INPUT(neuralnet).activation->buffer->sze_z,
                                  NEURALNET_INPUT(neuralnet).activation->buffer->sze_y,
                                  NEURALNET_INPUT(neuralnet).activation->buffer->sze_x, context);
    tensor_t output = tensor_alloc(SAMPLES, NEURALNET_OUTPUT(neuralnet).activation->buffer->sze_z,
                                   NEURALNET_OUTPUT(neuralnet).activation->buffer->sze_y,
                                   NEURALNET_OUTPUT(neuralnet).activation->buffer->sze_x, context);
    tensor_unary_random(&output);
    tensor_realize(&output);
    tensor_unary_random(&input);
    tensor_realize(&input);
    neuralnet_random(&neuralnet);

    neuralnet_forward(&neuralnet, &input);
    TENSOR_PRINT_(NEURALNET_OUTPUT(neuralnet).activation);

    neuralnet_free(&neuralnet);
    tensor_free(&input);
    tensor_free(&output);
    free(layerconfig);
    if(compile_type == compile_cl) {
        clReleaseDevice(device_id);
        clReleaseContext(context);
    }

    STOP_TIME();
    PRINT_TIME("main");

    return 0;
}
